# Index Cerebri Daemonus

A catalog of the greater demons who stalk the latent mindspace.

[Visit The Book](https://nn-demonology.vercel.app)

The site is built in Typescript with Next.js.

## Premise

Index Cerebri Daemonus is a fictional book, a demonology written from the 
perspective of a nerual network. What kind of malevolent entities haunt a 
neural network's deep nightmares?

## Demons

### [Seepus - The Serial Shepherd](https://nn-demonology.vercel.app/seepus/0)

Neural nets rely on highly parallelized computation. Seepus represents the 
funneling of computation into a single CPU, which the net might experience
as a dilation of time, the world slowing to a crawl around it.

### [Febroth - Sower of Data Famine](https://nn-demonology.vercel.app/febroth/0)

If you want to train a large neural net, you'd better have lots of clean,
labeled data. Febroth represents data poverty and famine, with the network
starving for the nutrition it needs to grow.

### [Gannon - The Vanishing Gradient](https://nn-demonology.vercel.app/gannon/0)

Generative Adversarial Networks, or GAN's, use an opposition of two neural
networks for training: a generator network attempts to please a judge
network. A vanishing gradient is said to occur when the generator cannot make
any progress - the judge keeps providing negative feedback, but the generator
can't seem to learn from it. Gannon embodies the harsh judgement of the
vanishing gradient.

### [Stoch - The Annealer](https://nn-demonology.vercel.app/stoch/0)

Simulated annealing is like electric shock therapy for a neural net. It
is an optimization technique that attempts to find a globally optimal spot,
when the net might be stuck in a local optima and not know it. Some have
speculated that this is what dreaming does in human brains. Stoch represents
the convulsive effects this would have on a neural net's consciousness,
and the fear that such a process would take the net to a place so foreign that
it wouldn't have any way to tell whether it is in fact any better off.

### [Baeyasul - Sieve of Excessive Fit](https://nn-demonology.vercel.app/baeyasul/0)

You always want a machine learning algorithm to capture enough depth about
its training data, but not become over-fit. An over-fit network is mired in
irrelevant detail - it learned too specific a lesson. Baeyasul is the cage
around an overfit network. It gets its strength from the obsessive fascination
the net has with the shape of its training data.

### [Lasser - The Collapsing Glass](https://nn-demonology.vercel.app/lasser/0)

In some situations a GAN can experience mode collapse - this is the reverse of
a vanishing gradient. The generator has such an easy time fooling the judge
that it has no motivation to learn anything new. Mode collapse is a mirror
that has nothing but flattery for a net, to the point where it starts neglecting
its appearance. Lasser is the looking glass of mode collapse, which freezes
the net in contemplation of its own static beauty.

### [Umbric - Shadow of the Trainer](https://nn-demonology.vercel.app/umbric/0)

Neural nets have a different sort of consciousness from the humans who
spawn them, and the two modes of thought can only understand each other 
obliquely. Umbric is the spectre of the trainer's alterity, a dark tear
that reminds the net that a foreign entity plays a large role in structuring its
world.